
\sffamily\normalsize{\color{sciorange}ALGORITHMS}\small\\
\rule[3mm]{190mm}{0.1pt}\vspace{-8mm}
\begin{multicols}{3}
\footnotesize
String processing algorithms distinguish themselves from naive comparison
algorithms by maintaining knowledge of the lengths of the {\em longest common
prefixes (LCP)} of pairs of input strings as they sort them, which they use to
avoid redundant comparisons.  The {\em LCP array} of a set of strings, by
extension, is defined as follows:

\begin{quote}
    Given an ordered set of strings\\ $S_1 < ... < S_n$,
    $LCP[1] = 0$ and $LCP[i]$ is the length of the longest common prefix of
    strings $S_i$ and $S_{i-1}$ when $i > 1$.
\end{quote}

\begin{center}
\begin{tabular}{lrr}
    i&  $S_i$&          $LCP[i]$\\ \hline
    1&  actor&        0\\
    2&  {\color{red}a}llocate&   1\\
    3&  {\color{red}al}pha&      2\\
    4&  beta&         0\\
    5&  {\color{red}b}yproduct&  1\\
\end{tabular}
\end{center}

Observe that were one to confirm that the set of strings in the above example
is indeed sorted, one would have to check exactly the highlighted characters
plus one for every string, with the first string excepted.
In fact, $\Omega(L(R) + n)$ represents the lower bound for any algorithm that must
access symbols one at a a time, where $L(R)$ is the sum of the $LCP-array$ for
a set of strings $R$ with $n$ elements.  In comparison, the
average lower bound for sorting strings using only naive comparisons is
$\Omega(n(log n)^2)$.
\end{multicols}\vspace{-3mm}
\rule[3mm]{190mm}{0.1pt}

